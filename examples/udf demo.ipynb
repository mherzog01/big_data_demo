{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17aa5a4c-c74f-489a-aa2f-749237f1bf56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T12:02:17.070064Z",
     "iopub.status.busy": "2022-04-21T12:02:17.069686Z",
     "iopub.status.idle": "2022-04-21T12:02:17.864364Z",
     "shell.execute_reply": "2022-04-21T12:02:17.862720Z",
     "shell.execute_reply.started": "2022-04-21T12:02:17.070020Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc7d55104394bfcaaaae888cc598947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+------------+\n",
      "|slen(name)|to_upper(name)|add_one(age)|\n",
      "+----------+--------------+------------+\n",
      "|         8|      JOHN DOE|          22|\n",
      "+----------+--------------+------------+"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "slen = F.udf(lambda s: len(s), IntegerType())\n",
    "@F.udf\n",
    "def to_upper(s):\n",
    "    if s is not None:\n",
    "        return s.upper()\n",
    "\n",
    "@F.udf(returnType=IntegerType())\n",
    "def add_one(x):\n",
    "    if x is not None:\n",
    "        return x + 1\n",
    "\n",
    "df = spark.createDataFrame([(1, \"John Doe\", 21)], (\"id\", \"name\", \"age\"))\n",
    "df.select(slen(\"name\").alias(\"slen(name)\"), to_upper(\"name\"), add_one(\"age\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9efc654e-33e7-494f-82a2-f37013877a2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T12:02:26.275273Z",
     "iopub.status.busy": "2022-04-21T12:02:26.275012Z",
     "iopub.status.idle": "2022-04-21T12:02:27.051575Z",
     "shell.execute_reply": "2022-04-21T12:02:27.050889Z",
     "shell.execute_reply.started": "2022-04-21T12:02:26.275247Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "521e752227284bd48472e4dd3d73cb49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+-------+-------+\n",
      "|    name|age|f1(age)|f2(age)|\n",
      "+--------+---+-------+-------+\n",
      "|John Doe| 21|     42|     23|\n",
      "+--------+---+-------+-------+"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/a/69215982/11262633\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml.linalg import DenseVector, VectorUDT\n",
    "\n",
    "@F.udf(returnType=IntegerType())\n",
    "def f1(x):\n",
    "    return x * 2\n",
    "\n",
    "@F.udf(returnType=IntegerType())\n",
    "def f2(x):\n",
    "    return x + 2\n",
    "\n",
    "@F.udf(returnType=IntegerType())\n",
    "def f3(x):\n",
    "    return f1(x) * f2(x) \n",
    "\n",
    "df.select('name', 'age', f1('age'), f2('age')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6dfc0c2-b694-483b-a842-623d293cb588",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T12:05:33.183211Z",
     "iopub.status.busy": "2022-04-21T12:05:33.182966Z",
     "iopub.status.idle": "2022-04-21T12:05:33.244698Z",
     "shell.execute_reply": "2022-04-21T12:05:33.244076Z",
     "shell.execute_reply.started": "2022-04-21T12:05:33.183181Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a615d3583e0e406f9c97ca9e225b9296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "Column is not iterable\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/column.py\", line 460, in __iter__\n",
      "    raise TypeError(\"Column is not iterable\")\n",
      "TypeError: Column is not iterable\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for v in f2(F.lit(5)):\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8da7950-3df2-42b6-9855-a286ffd15d79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T12:18:49.003567Z",
     "iopub.status.busy": "2022-04-21T12:18:49.003311Z",
     "iopub.status.idle": "2022-04-21T12:18:49.276229Z",
     "shell.execute_reply": "2022-04-21T12:18:49.275547Z",
     "shell.execute_reply.started": "2022-04-21T12:18:49.003538Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6f076517f164271b49bb2119d295927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "Could not serialize object: TypeError: can't pickle _thread.RLock objects\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/udf.py\", line 199, in wrapper\n",
      "    return self(*args)\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/udf.py\", line 177, in __call__\n",
      "    judf = self._judf\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/udf.py\", line 161, in _judf\n",
      "    self._judf_placeholder = self._create_judf()\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/udf.py\", line 170, in _create_judf\n",
      "    wrapped_func = _wrap_function(sc, self.func, self.returnType)\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/udf.py\", line 34, in _wrap_function\n",
      "    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/rdd.py\", line 2814, in _prepare_for_python_RDD\n",
      "    pickled_command = ser.dumps(command)\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 447, in dumps\n",
      "    raise pickle.PicklingError(msg)\n",
      "_pickle.PicklingError: Could not serialize object: TypeError: can't pickle _thread.RLock objects\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('name', 'age', f3('age')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18a9677a-f0d1-4c10-809d-81b38eb3d905",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T12:19:23.633401Z",
     "iopub.status.busy": "2022-04-21T12:19:23.633182Z",
     "iopub.status.idle": "2022-04-21T12:19:23.686233Z",
     "shell.execute_reply": "2022-04-21T12:19:23.685706Z",
     "shell.execute_reply.started": "2022-04-21T12:19:23.633377Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaf34d2862cd425a956f048ec97a3d95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def nested_f(x):\n",
    "    return x + 1\n",
    "\n",
    "def main_f(x):\n",
    "    return nested_f(x) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eae21b9c-6ed6-4383-a046-95d931935fb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T12:20:51.722787Z",
     "iopub.status.busy": "2022-04-21T12:20:51.722541Z",
     "iopub.status.idle": "2022-04-21T12:21:01.030495Z",
     "shell.execute_reply": "2022-04-21T12:21:01.029918Z",
     "shell.execute_reply.started": "2022-04-21T12:20:51.722759Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e7ad357121942e58afbc306a0226d60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "|  x| x1|\n",
      "+---+---+\n",
      "|  1|  3|\n",
      "|  2|  4|\n",
      "|  3|  5|\n",
      "+---+---+"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/55688664/calling-another-custom-python-function-from-pyspark-udf\n",
    "df = spark.createDataFrame([[1], [2], [3]],['x'])\n",
    "\n",
    "_udf = F.udf(main_f, 'int')\n",
    "df.withColumn('x1', _udf(df['x'])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6323701d-c6c4-4522-8690-ee17e0b92fb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T12:22:05.793329Z",
     "iopub.status.busy": "2022-04-21T12:22:05.793084Z",
     "iopub.status.idle": "2022-04-21T12:22:05.847917Z",
     "shell.execute_reply": "2022-04-21T12:22:05.847181Z",
     "shell.execute_reply.started": "2022-04-21T12:22:05.793302Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "864b49a76ca540f380e9975af03aed4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def p_f1(x):\n",
    "    return x * 2\n",
    "\n",
    "def p_f2(x):\n",
    "    return x + 2\n",
    "\n",
    "def p_f3(x):\n",
    "    return p_f1(x) * p_f2(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32498944-1db7-4886-996d-87e458df17b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T16:05:43.656839Z",
     "iopub.status.busy": "2022-04-21T16:05:43.656605Z",
     "iopub.status.idle": "2022-04-21T16:05:43.698657Z",
     "shell.execute_reply": "2022-04-21T16:05:43.698122Z",
     "shell.execute_reply.started": "2022-04-21T16:05:43.656813Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8c893bf02aa44cc8eba211645667a47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "Invalid status code '404' from http://localhost:8998/sessions/1 with error payload: {\"msg\":\"Session '1' not found.\"}\n"
     ]
    }
   ],
   "source": [
    "_udf = F.udf(p_f3, 'int')\n",
    "df.withColumn('x1', _udf(df['x'])).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
