{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4cd82a0-48d0-40c9-bf19-9dfef602acbf",
   "metadata": {},
   "source": [
    "# s3-dist-cp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babee3c4-945c-4757-a565-eba96d2207c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get an image\n",
    "\n",
    "Use ```s3-dist-cp``` to copy an image to HDFS\n",
    "\n",
    "Reference:  https://docs.aws.amazon.com/emr/latest/ReleaseGuide/UsingEMR_s3distcp.html\n",
    "Blog:  https://aws.amazon.com/blogs/big-data/seven-tips-for-using-s3distcp-on-amazon-emr-to-move-data-efficiently-between-hdfs-and-amazon-s3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "192898b9-8baa-4c6b-bd44-ec33eaabf02e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T02:39:22.302639Z",
     "iopub.status.busy": "2022-04-14T02:39:22.302405Z",
     "iopub.status.idle": "2022-04-14T02:39:22.360207Z",
     "shell.execute_reply": "2022-04-14T02:39:22.359511Z",
     "shell.execute_reply.started": "2022-04-14T02:39:22.302612Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java: /usr/bin/java /usr/lib/java /etc/java /usr/share/java\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "openjdk version \"1.8.0_322\"\n",
      "OpenJDK Runtime Environment Corretto-8.322.06.3 (build 1.8.0_322-b06)\n",
      "OpenJDK 64-Bit Server VM Corretto-8.322.06.3 (build 25.322-b06, mixed mode)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "java -version\n",
    "whereis java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3a16dd26-e222-4c3f-80bf-e5d88b6e3d41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T02:42:20.121280Z",
     "iopub.status.busy": "2022-04-14T02:42:20.121035Z",
     "iopub.status.idle": "2022-04-14T02:42:22.142642Z",
     "shell.execute_reply": "2022-04-14T02:42:22.141835Z",
     "shell.execute_reply.started": "2022-04-14T02:42:20.121256Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 items\n",
      "-rw-r--r--   1 hadoop hdfsadmingroup      40382 2022-04-14 02:31 /tmp/00024a73d1a4c32fb29732d56a2.jpg\n",
      "drwxrwxrwt   - yarn   hdfsadmingroup          0 2022-04-13 21:53 /tmp/entity-file-history\n",
      "drwxrwxrwx   - mapred mapred                  0 2022-04-13 21:52 /tmp/hadoop-yarn\n",
      "drwx-wx-wx   - hive   hdfsadmingroup          0 2022-04-13 21:53 /tmp/hive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/usr/share/aws/emr/emrfs/lib/slf4j-log4j12-1.7.12.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "export JAVA_HOME=/usr\n",
    "hadoop fs -ls /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b0ef655e-d39c-4c53-a674-f2a296350776",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T02:25:13.929769Z",
     "iopub.status.busy": "2022-04-14T02:25:13.929538Z",
     "iopub.status.idle": "2022-04-14T02:25:14.832398Z",
     "shell.execute_reply": "2022-04-14T02:25:14.831751Z",
     "shell.execute_reply.started": "2022-04-14T02:25:13.929743Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-31 01:07:42      40382 00024a73d1a4c32fb29732d56a2.jpg\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"s3://multimedia-commons/data/images/000/24a/00024a73d1a4c32fb29732d56a2.jpg\"\n",
    "aws s3 ls \"$1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "77d95b5e-988c-4074-996f-e656a4848f25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T02:33:01.551213Z",
     "iopub.status.busy": "2022-04-14T02:33:01.550985Z",
     "iopub.status.idle": "2022-04-14T02:33:42.880023Z",
     "shell.execute_reply": "2022-04-14T02:33:42.878927Z",
     "shell.execute_reply.started": "2022-04-14T02:33:01.551189Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/usr/share/aws/emr/emrfs/lib/slf4j-log4j12-1.7.12.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n",
      "2022-04-14 02:33:02,198 INFO s3distcp.Main: Running with args: -libjars /usr/share/aws/emr/s3-dist-cp/lib/aopalliance-1.0.jar,/usr/share/aws/emr/s3-dist-cp/lib/guava-18.0.jar,/usr/share/aws/emr/s3-dist-cp/lib/guice-4.1.0.jar,/usr/share/aws/emr/s3-dist-cp/lib/guice-servlet-4.2.3.jar,/usr/share/aws/emr/s3-dist-cp/lib/javax.inject-1.jar,/usr/share/aws/emr/s3-dist-cp/lib/s3-dist-cp-2.19.0.jar,/usr/share/aws/emr/s3-dist-cp/lib/s3-dist-cp.jar --src s3://multimedia-commons/data/images/000/24a/00024a73d1a4c32fb29732d56a2.jpg --dest /tmp --s3Endpoint=s3.us-west-2.amazonaws.com \n",
      "2022-04-14 02:33:02,539 INFO s3distcp.S3DistCp: S3DistCp args: --src s3://multimedia-commons/data/images/000/24a/00024a73d1a4c32fb29732d56a2.jpg --dest /tmp --s3Endpoint=s3.us-west-2.amazonaws.com\n",
      "2022-04-14 02:33:02,543 INFO s3distcp.S3DistCp: Using output path 'hdfs:/tmp/c0630929-9053-43b2-abc7-677bea50cdd7/output'\n",
      "2022-04-14 02:33:02,543 INFO s3distcp.S3DistCp: Try to recursively delete with throw Exceptionhdfs:/tmp/c0630929-9053-43b2-abc7-677bea50cdd7/files\n",
      "2022-04-14 02:33:02,944 INFO s3distcp.S3DistCp: Try to recursively delete with throw Exceptionhdfs:/tmp/c0630929-9053-43b2-abc7-677bea50cdd7/output\n",
      "2022-04-14 02:33:05,353 INFO s3distcp.S3ClientFactory: Create Amazon S3 client with endpoint override\n",
      "2022-04-14 02:33:05,717 INFO s3distcp.S3ClientFactory: DefaultAWSCredentialsProviderChain is used to create AmazonS3Client.\n",
      "2022-04-14 02:33:05,717 INFO s3distcp.S3ClientFactory: Overrides Amazon S3 Endpoint with s3.us-west-2.amazonaws.com\n",
      "2022-04-14 02:33:05,892 INFO s3distcp.S3DistCp: Get src prefix s3://multimedia-commons/data/images/000/24a/00024a73d1a4c32fb29732d56a2.jpg endWithSlash false\n",
      "2022-04-14 02:33:05,892 INFO s3distcp.S3DistCp: Only a single prefix is got\n",
      "2022-04-14 02:33:05,894 INFO s3distcp.S3DistCp: listing objects in bucket multimedia-commons target prefix is data/images/000/24a/00024a73d1a4c32fb29732d56a2.jpg\n",
      "2022-04-14 02:33:06,370 INFO s3distcp.S3DistCp: Got object summary \n",
      " Bucket = multimedia-commons, Key = data/images/000/24a/00024a73d1a4c32fb29732d56a2.jpg\n",
      "2022-04-14 02:33:06,371 INFO s3distcp.FileInfoListing: Opening new file: hdfs:/tmp/c0630929-9053-43b2-abc7-677bea50cdd7/files/1\n",
      "2022-04-14 02:33:06,455 INFO s3distcp.S3DistCp: Created 1 files to copy 1 files \n",
      "2022-04-14 02:33:06,559 INFO s3distcp.S3DistCp: Reducer number: 3\n",
      "2022-04-14 02:33:06,758 INFO client.RMProxy: Connecting to ResourceManager at ip-172-31-22-43.us-east-2.compute.internal/172.31.22.43:8032\n",
      "2022-04-14 02:33:06,929 INFO client.AHSProxy: Connecting to Application History server at ip-172-31-22-43.us-east-2.compute.internal/172.31.22.43:10200\n",
      "2022-04-14 02:33:07,009 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/emr-notebook/.staging/job_1649886739542_0016\n",
      "2022-04-14 02:33:07,226 INFO input.FileInputFormat: Total input files to process : 1\n",
      "2022-04-14 02:33:07,285 INFO mapreduce.JobSubmitter: number of splits:1\n",
      "2022-04-14 02:33:07,498 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1649886739542_0016\n",
      "2022-04-14 02:33:07,500 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
      "2022-04-14 02:33:08,055 INFO conf.Configuration: resource-types.xml not found\n",
      "2022-04-14 02:33:08,056 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\n",
      "2022-04-14 02:33:08,153 INFO impl.YarnClientImpl: Submitted application application_1649886739542_0016\n",
      "2022-04-14 02:33:08,190 INFO mapreduce.Job: The url to track the job: http://ip-172-31-22-43.us-east-2.compute.internal:20888/proxy/application_1649886739542_0016/\n",
      "2022-04-14 02:33:08,191 INFO mapreduce.Job: Running job: job_1649886739542_0016\n",
      "2022-04-14 02:33:14,248 INFO mapreduce.Job: Job job_1649886739542_0016 running in uber mode : false\n",
      "2022-04-14 02:33:14,250 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "2022-04-14 02:33:19,297 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "2022-04-14 02:33:22,312 INFO mapreduce.Job: Task Id : attempt_1649886739542_0016_r_000000_0, Status : FAILED\n",
      "Error: java.lang.RuntimeException: Reducer task failed to copy 1 files: s3://multimedia-commons/data/images/000/24a/00024a73d1a4c32fb29732d56a2.jpg etc\n",
      "\tat com.amazon.elasticmapreduce.s3distcp.CopyFilesReducer.cleanup(CopyFilesReducer.java:64)\n",
      "\tat org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:179)\n",
      "\tat org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:636)\n",
      "\tat org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:391)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "2022-04-14 02:33:26,343 INFO mapreduce.Job:  map 100% reduce 33%\n",
      "2022-04-14 02:33:29,355 INFO mapreduce.Job:  map 100% reduce 67%\n",
      "2022-04-14 02:33:31,365 INFO mapreduce.Job: Task Id : attempt_1649886739542_0016_r_000000_1, Status : FAILED\n",
      "Error: java.lang.RuntimeException: Reducer task failed to copy 1 files: s3://multimedia-commons/data/images/000/24a/00024a73d1a4c32fb29732d56a2.jpg etc\n",
      "\tat com.amazon.elasticmapreduce.s3distcp.CopyFilesReducer.cleanup(CopyFilesReducer.java:64)\n",
      "\tat org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:179)\n",
      "\tat org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:636)\n",
      "\tat org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:391)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "2022-04-14 02:33:36,385 INFO mapreduce.Job: Task Id : attempt_1649886739542_0016_r_000000_2, Status : FAILED\n",
      "Error: java.lang.RuntimeException: Reducer task failed to copy 1 files: s3://multimedia-commons/data/images/000/24a/00024a73d1a4c32fb29732d56a2.jpg etc\n",
      "\tat com.amazon.elasticmapreduce.s3distcp.CopyFilesReducer.cleanup(CopyFilesReducer.java:64)\n",
      "\tat org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:179)\n",
      "\tat org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:636)\n",
      "\tat org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:391)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "2022-04-14 02:33:42,412 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "2022-04-14 02:33:42,419 INFO mapreduce.Job: Job job_1649886739542_0016 failed with state FAILED due to: Task failed task_1649886739542_0016_r_000000\n",
      "Job failed as tasks failed. failedMaps:0 failedReduces:1 killedMaps:0 killedReduces: 0\n",
      "\n",
      "2022-04-14 02:33:42,494 INFO mapreduce.Job: Counters: 55\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=40\n",
      "\t\tFILE: Number of bytes written=734544\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=419\n",
      "\t\tHDFS: Number of bytes written=0\n",
      "\t\tHDFS: Number of read operations=14\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=4\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tFailed reduce tasks=4\n",
      "\t\tLaunched map tasks=1\n",
      "\t\tLaunched reduce tasks=6\n",
      "\t\tData-local map tasks=1\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=273024\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=2568000\n",
      "\t\tTotal time spent by all map tasks (ms)=2844\n",
      "\t\tTotal time spent by all reduce tasks (ms)=13375\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=2844\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=13375\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=8736768\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=82176000\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1\n",
      "\t\tMap output records=1\n",
      "\t\tMap output bytes=182\n",
      "\t\tMap output materialized bytes=149\n",
      "\t\tInput split bytes=168\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=0\n",
      "\t\tReduce shuffle bytes=32\n",
      "\t\tReduce input records=0\n",
      "\t\tReduce output records=0\n",
      "\t\tSpilled Records=1\n",
      "\t\tShuffled Maps =2\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tGC time elapsed (ms)=489\n",
      "\t\tCPU time spent (ms)=1810\n",
      "\t\tPhysical memory (bytes) snapshot=1319415808\n",
      "\t\tVirtual memory (bytes) snapshot=18570838016\n",
      "\t\tTotal committed heap usage (bytes)=1402994688\n",
      "\t\tPeak Map Physical memory (bytes)=801112064\n",
      "\t\tPeak Map Virtual memory (bytes)=4397477888\n",
      "\t\tPeak Reduce Physical memory (bytes)=273403904\n",
      "\t\tPeak Reduce Virtual memory (bytes)=7087341568\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=251\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2022-04-14 02:33:42,495 INFO s3distcp.S3DistCp: Try to recursively delete without throw Exceptionhdfs:/tmp/c0630929-9053-43b2-abc7-677bea50cdd7\n",
      "2022-04-14 02:33:42,504 ERROR s3distcp.S3DistCp: The MapReduce job failed: Task failed task_1649886739542_0016_r_000000\n",
      "Job failed as tasks failed. failedMaps:0 failedReduces:1 killedMaps:0 killedReduces: 0\n",
      "\n",
      "Exception in thread \"main\" java.lang.RuntimeException: The MapReduce job failed: Task failed task_1649886739542_0016_r_000000\n",
      "Job failed as tasks failed. failedMaps:0 failedReduces:1 killedMaps:0 killedReduces: 0\n",
      "\n",
      "\tat com.amazon.elasticmapreduce.s3distcp.S3DistCp.run(S3DistCp.java:301)\n",
      "\tat com.amazon.elasticmapreduce.s3distcp.S3DistCp.run(S3DistCp.java:69)\n",
      "\tat org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)\n",
      "\tat org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:90)\n",
      "\tat com.amazon.elasticmapreduce.s3distcp.Main.main(Main.java:21)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.util.RunJar.run(RunJar.java:323)\n",
      "\tat org.apache.hadoop.util.RunJar.main(RunJar.java:236)\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b's3-dist-cp --src \"$1\" --dest /tmp --s3Endpoint=s3.us-west-2.amazonaws.com\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-37f9fea41f6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-s \"s3://multimedia-commons/data/images/000/24a/00024a73d1a4c32fb29732d56a2.jpg\"'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m's3-dist-cp --src \"$1\" --dest /tmp --s3Endpoint=s3.us-west-2.amazonaws.com\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/notebook-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2401\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2402\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2403\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2404\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/notebook-env/lib/python3.7/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/notebook-env/lib/python3.7/site-packages/decorator.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/notebook-env/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/notebook-env/lib/python3.7/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b's3-dist-cp --src \"$1\" --dest /tmp --s3Endpoint=s3.us-west-2.amazonaws.com\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash -s \"s3://multimedia-commons/data/images/000/24a/00024a73d1a4c32fb29732d56a2.jpg\"\n",
    "s3-dist-cp --src \"$1\" --dest /tmp --s3Endpoint=s3.us-west-2.amazonaws.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
