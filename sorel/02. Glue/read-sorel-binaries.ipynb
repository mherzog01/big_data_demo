{"metadata":{"kernelspec":{"name":"glue_pyspark","display_name":"Glue PySpark","language":"python"},"language_info":{"name":"Python_Glue_Session","mimetype":"text/x-python","codemirror_mode":{"name":"python","version":3},"pygments_lexer":"python3","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Read SOREL data\n##### You are now running a AWS Glue Studio notebook; To start using your notebook you need to start an AWS Glue Interactive Session.\n","metadata":{"editable":true,"trusted":true}},{"cell_type":"markdown","source":"#### Optional: Run this cell to see available notebook commands (\"magics\").\n","metadata":{"editable":true,"trusted":true}},{"cell_type":"code","source":"%help","metadata":{"editable":true,"tags":[],"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 0.37.0 \n","output_type":"stream"},{"output_type":"display_data","data":{"text/markdown":"\n# Available Magic Commands\n\n## Sessions Magic\n\n----\n    %help                             Return a list of descriptions and input types for all magic commands. \n    %profile            String        Specify a profile in your aws configuration to use as the credentials provider.\n    %region             String        Specify the AWS region in which to initialize a session. \n                                      Default from ~/.aws/config on Linux or macOS, \n                                      or C:\\Users\\ USERNAME \\.aws\\config\" on Windows.\n    %idle_timeout       Int           The number of minutes of inactivity after which a session will timeout. \n                                      Default: 2880 minutes (48 hours).\n    %session_id_prefix  String        Define a String that will precede all session IDs in the format \n                                      [session_id_prefix]-[session_id]. If a session ID is not provided,\n                                      a random UUID will be generated.\n    %status                           Returns the status of the current Glue session including its duration, \n                                      configuration and executing user / role.\n    %session_id                       Returns the session ID for the running session. \n    %list_sessions                    Lists all currently running sessions by ID.\n    %stop_session                     Stops the current session.\n    %glue_version       String        The version of Glue to be used by this session. \n                                      Currently, the only valid options are 2.0 and 3.0. \n                                      Default: 2.0.\n----\n\n## Selecting Job Types\n\n----\n    %streaming          String        Sets the session type to Glue Streaming.\n    %etl                String        Sets the session type to Glue ETL.\n    %glue_ray           String        Sets the session type to Glue Ray.\n----\n\n## Glue Config Magic \n*(common across all job types)*\n\n----\n\n    %%configure         Dictionary    A json-formatted dictionary consisting of all configuration parameters for \n                                      a session. Each parameter can be specified here or through individual magics.\n    %iam_role           String        Specify an IAM role ARN to execute your session with.\n                                      Default from ~/.aws/config on Linux or macOS, \n                                      or C:\\Users\\%USERNAME%\\.aws\\config` on Windows.\n    %number_of_workers  int           The number of workers of a defined worker_type that are allocated \n                                      when a session runs.\n                                      Default: 5.\n    %additional_python_modules  List  Comma separated list of additional Python modules to include in your cluster \n                                      (can be from Pypi or S3).\n----\n\n                                      \n## Magic for Spark Jobs (ETL & Streaming)\n\n----\n    %worker_type        String        Set the type of instances the session will use as workers. \n                                      ETL and Streaming support G.1X and G.2X. \n                                      Default: G.1X.\n    %connections        List          Specify a comma separated list of connections to use in the session.\n    %extra_py_files     List          Comma separated list of additional Python files From S3.\n    %extra_jars         List          Comma separated list of additional Jars to include in the cluster.\n    %spark_conf         String        Specify custom spark configurations for your session. \n                                      E.g. %spark_conf spark.serializer=org.apache.spark.serializer.KryoSerializer\n----\n                                      \n## Magic for Ray Job\n\n----\n    %min_workers        Int           The minimum number of workers that are allocated to a Ray job. \n                                      Default: 1.\n    %object_memory_head Int           The percentage of free memory on the instance head node after a warm start. \n                                      Minimum: 0. Maximum: 100.\n    %object_memory_worker Int         The percentage of free memory on the instance worker nodes after a warm start. \n                                      Minimum: 0. Maximum: 100.\n----\n\n## Action Magic\n\n----\n\n    %%sql               String        Run SQL code. All lines after the initial %%sql magic will be passed\n                                      as part of the SQL code.  \n----\n\n"},"metadata":{}}]},{"cell_type":"markdown","source":"####  Run this cell to set up and start your interactive session.\n","metadata":{"editable":true,"trusted":true}},{"cell_type":"code","source":"%idle_timeout 2880\n%glue_version 3.0\n%worker_type G.1X\n%number_of_workers 5\n\nimport sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\n\nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)","metadata":{"editable":true,"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 0.37.0 \nCurrent idle_timeout is 2800 minutes.\nidle_timeout has been set to 2880 minutes.\nSetting Glue version to: 3.0\nPrevious worker type: G.1X\nSetting new worker type to: G.1X\nPrevious number of workers: 5\nSetting new number of workers to: 5\nAuthenticating with environment variables and user-defined glue_role_arn: arn:aws:iam::883375387566:role/glue-full-access\nTrying to create a Glue session for the kernel.\nWorker Type: G.1X\nNumber of Workers: 5\nSession ID: 3edbd1f0-507c-4f00-8fce-5efe9815f4c8\nJob Type: glueetl\nApplying the following default arguments:\n--glue_kernel_version 0.37.0\n--enable-glue-datacatalog true\n","output_type":"stream"},{"name":"stderr","text":"Exception encountered while creating session: An error occurred (AlreadyExistsException) when calling the CreateSession operation: Session already created, sessionId=3edbd1f0-507c-4f00-8fce-5efe9815f4c8 \nTraceback (most recent call last):\n  File \"/home/jupyter-user/.local/lib/python3.7/site-packages/aws_glue_interactive_sessions_kernel/glue_pyspark/GlueKernel.py\", line 291, in do_execute\n    self.create_session()\n  File \"/home/jupyter-user/.local/lib/python3.7/site-packages/aws_glue_interactive_sessions_kernel/glue_pyspark/GlueKernel.py\", line 745, in create_session\n    **additional_args,\n  File \"/home/jupyter-user/.local/lib/python3.7/site-packages/botocore/client.py\", line 530, in _api_call\n    return self._make_api_call(operation_name, kwargs)\n  File \"/home/jupyter-user/.local/lib/python3.7/site-packages/botocore/client.py\", line 960, in _make_api_call\n    raise error_class(parsed_response, operation_name)\nbotocore.errorfactory.AlreadyExistsException: An error occurred (AlreadyExistsException) when calling the CreateSession operation: Session already created, sessionId=3edbd1f0-507c-4f00-8fce-5efe9815f4c8\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Create RDD using sc.binaryFiles\n","metadata":{"editable":true,"trusted":true}},{"cell_type":"code","source":"#dyf = glueContext.create_dynamic_frame.from_catalog(database='database_name', table_name='table_name')\n#dyf.printSchema()\n\nimport pyspark\n  \n# TODO Pass job parameters externally\n#args={\"s3_bucket\": \"sorel-20m\", \"s3_key\": \"09-DEC-2020/binaries/0000029bfead495a003e43a7ab8406c6209ffb7d5e59dd212607aa358bfd66ea\"}\nargs={\"s3_bucket\": \"sorel-20m\", \"s3_key\": \"09-DEC-2020/binaries\"}\n\n'''\n2020-12-01 20:39:23     179128 0000029bfead495a003e43a7ab8406c6209ffb7d5e59dd212607aa358bfd66ea\n2020-12-01 20:39:23       1786 000003b99c3d4b9860ad0b0ca43450603e5322f2cca3c9b3d543a2d6440305a0\n2020-12-01 20:39:23    2687186 00000533148c26bcc09ab44b1acafe32dde93773d4a7e3dbd06c8232db5e437f\n2020-12-01 20:39:23     154064 000005920ff4eb85cfc74fd51ef1d5d7518dc16f6cb5c53f94f619473321d594\n2020-12-01 20:39:23     170646 000008cf1b5ecbed74f31b45e96e0fb6566b6af75a5cd87335aaa91c20a9b822\n2020-12-01 20:39:23     105479 000008e2ff1b8d64e3f81cbc456d4d51b6e967af0267d5486d4a562df291d0a6\n2020-12-01 20:39:23      44960 00000b37a3d68384e9ce2c8f969ba3d839514ec6d3b234ed2285dff2aee644bd\n2020-12-01 20:39:23     553005 00000cae80bac4c4591dd2f4451d0d1543ecd8d62eb8bcdc22a6bd45ba738d7d\n2020-12-01 20:39:23      70200 0000119640135ca4b5ee0d21459a1f841b9c030a88513581a272fc4740d78f48\n2020-12-01 20:39:29     489842 0000130e0c5d788a51b1c7e519b0883f0d34485076f9ceb11c1cda4929dffb31\n'''\n\nbucket = args['s3_bucket']\nkey = args['s3_key']\n\n#spark = pyspark.sql.SparkSession(sc)\n\n#binary_rdd = sc.binaryFiles(\"s3://{}/{}\".format(bucket, key))\n\n# do something with the binary_rdd\n","metadata":{"editable":true,"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"df = binary_rdd.toDF()\ndf.count()","metadata":{"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Execution Interrupted. Attempting to cancel the statement (statement_id=2)\nStatement 2 has been cancelled\n","output_type":"stream"}]},{"cell_type":"code","source":"df2 = df.filter(df._1 == 's3://sorel-20m-demo/tmp/binaries/0000029bfead495a003e43a7ab8406c6209ffb7d5e59dd212607aa358bfd66ea')\nrows2 = df2.collect()\nrows2[0]['_1']","metadata":{"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Execution Interrupted. Attempting to cancel the statement (statement_id=3)\nStatement 3 has been cancelled\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Small amounts of data","metadata":{}},{"cell_type":"markdown","source":"## Read text files to a DataFrame","metadata":{"tags":[]}},{"cell_type":"code","source":"text_df = spark.read.format(\"text\").load(\"s3://sorel-20m-demo/emr-serverless-spark/output/\")","metadata":{"tags":[],"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"text_df.count()","metadata":{"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"82260\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Read binary files","metadata":{}},{"cell_type":"code","source":"#binary_df = sc.read.format(\"binaryFile\").option(\"pathGlobFilter\", \"0000*\").load(\"s3://sorel-20m-demo/tmp/binaries/\")\nbinary_df = spark.read.format(\"binaryFile\").load(\"s3://sorel-20m-demo/tmp/binaries/\")","metadata":{"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"binary_df.count()","metadata":{"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"175\n","output_type":"stream"}]},{"cell_type":"code","source":"binary_df.head(1).show()","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Execution Interrupted. Attempting to cancel the statement (statement_id=14)\nStatement 14 has been cancelled\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Filter","metadata":{}},{"cell_type":"code","source":"binary_df2 = spark.read.format(\"binaryFile\").option('pathGlobFilter', '0000029*').load(\"s3://sorel-20m-demo/tmp/binaries/\")","metadata":{"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"binary_df2.count()","metadata":{"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"1\n","output_type":"stream"}]},{"cell_type":"code","source":"binary_df2.show()","metadata":{"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"+--------------------+-------------------+------+--------------------+\n|                path|   modificationTime|length|             content|\n+--------------------+-------------------+------+--------------------+\n|s3://sorel-20m-de...|2023-03-16 01:48:37|179128|[78 9C EC BD 0D 7...|\n+--------------------+-------------------+------+--------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"binary_df3 = binary_df.filter(binary_df.path == 's3://sorel-20m-demo/tmp/binaries/0000029bfead495a003e43a7ab8406c6209ffb7d5e59dd212607aa358bfd66ea')\nbinary_df3.count()","metadata":{"tags":[],"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# The large bucket","metadata":{}},{"cell_type":"code","source":"df = spark.read.format(\"binaryFile\").option('pathGlobFilter', '0000029*').load(\"s3://sorel-20m/09-DEC-2020/binaries\")\ndf.count()","metadata":{"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Execution Interrupted. Attempting to cancel the statement (statement_id=22)\n","output_type":"stream"}]},{"cell_type":"code","source":"df2 = df.filter($_1.like('s3://sorel-20m-demo/tmp/binaries/00000%')\nrows2 = df2.collect()\nrows2[0]['_1']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Example: Convert the DynamicFrame to a Spark DataFrame and display a sample of the data\n","metadata":{"editable":true,"trusted":true}},{"cell_type":"code","source":"df = dyf.toDF()\ndf.show()","metadata":{"editable":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Example: Write the data in the DynamicFrame to a location in Amazon S3 and a table for it in the AWS Glue Data Catalog\n","metadata":{"editable":true,"trusted":true}},{"cell_type":"code","source":"s3output = glueContext.getSink(\n  path=\"s3://bucket_name/folder_name\",\n  connection_type=\"s3\",\n  updateBehavior=\"UPDATE_IN_DATABASE\",\n  partitionKeys=[],\n  compression=\"snappy\",\n  enableUpdateCatalog=True,\n  transformation_ctx=\"s3output\",\n)\ns3output.setCatalogInfo(\n  catalogDatabase=\"demo\", catalogTableName=\"populations\"\n)\ns3output.setFormat(\"glueparquet\")\ns3output.writeFrame(DyF)","metadata":{"editable":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%status\n%list_sessions","metadata":{"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"There is no current session.\nThe first 25 sessions are:\n0aa03fd3-ab6f-4d85-b882-0be986a1fd22\n144285e4-a0c6-40c7-ad12-cd7df56562e3\n1816a59b-d194-41f3-9d12-02bf90a098c5\n1e367fb8-bf26-461f-b4b9-93a68db402b6\n260bffd6-27e8-4487-8fe9-e547b1f79a2d\n2fcace20-cec9-432d-9a60-6f67f5ff168b\n3a26e41a-f615-4e0b-af93-751f9f952e7b\n3edbd1f0-507c-4f00-8fce-5efe9815f4c8\n416957e6-debf-426a-bd40-eda3df323fad\n5618b7b1-d706-4b71-9aad-85dc985bd5fa\n5f3b1b5d-59eb-4114-9503-9b68058b4841\n62c54cec-660e-480b-b9cf-de0bc24f00dd\n6766e8da-9786-41fe-89a9-978c7d71a053\n697427db-8828-4441-82e9-e0cdf670eca0\n716a100f-e125-4d4b-b69a-d18724c86304\n82ae531d-206e-4d03-873e-f9733ec0cc71\n8692fbe3-e31c-43db-b4bd-7788c69fdf65\n8fd1ccd1-e001-463d-b26c-2c94b4d670d8\n94be9d3a-1aad-47df-8566-c4a786313278\naa598c53-03c6-4dc6-94be-5733e8cdd801\nbfe58f27-8c26-4e54-ac5c-7c5a81561e68\ncf345940-2c40-453e-9c3c-656dbd454444\nd832a791-052b-4491-bf7b-a4e4957a0c0e\nda84b4df-2bab-419b-904b-932edc29b267\ndf629284-b003-4637-822f-4e4d64339007\n","output_type":"stream"}]},{"cell_type":"code","source":"%stop_session","metadata":{"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"There is no current session.\n","output_type":"stream"}]}]}