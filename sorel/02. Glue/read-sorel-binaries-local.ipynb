{
	"metadata": {
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "markdown",
			"source": "# AWS Glue Studio Notebook\n##### You are now running a AWS Glue Studio notebook; To start using your notebook you need to start an AWS Glue Interactive Session.\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "markdown",
			"source": "#### Optional: Run this cell to see available notebook commands (\"magics\").\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%help",
			"metadata": {
				"editable": true,
				"tags": [],
				"trusted": true
			},
			"execution_count": 2,
			"outputs": [
				{
					"name": "stdout",
					"text": "Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 0.37.0 \n",
					"output_type": "stream"
				},
				{
					"output_type": "display_data",
					"data": {
						"text/markdown": "\n# Available Magic Commands\n\n## Sessions Magic\n\n----\n    %help                             Return a list of descriptions and input types for all magic commands. \n    %profile            String        Specify a profile in your aws configuration to use as the credentials provider.\n    %region             String        Specify the AWS region in which to initialize a session. \n                                      Default from ~/.aws/config on Linux or macOS, \n                                      or C:\\Users\\ USERNAME \\.aws\\config\" on Windows.\n    %idle_timeout       Int           The number of minutes of inactivity after which a session will timeout. \n                                      Default: 2880 minutes (48 hours).\n    %session_id_prefix  String        Define a String that will precede all session IDs in the format \n                                      [session_id_prefix]-[session_id]. If a session ID is not provided,\n                                      a random UUID will be generated.\n    %status                           Returns the status of the current Glue session including its duration, \n                                      configuration and executing user / role.\n    %session_id                       Returns the session ID for the running session. \n    %list_sessions                    Lists all currently running sessions by ID.\n    %stop_session                     Stops the current session.\n    %glue_version       String        The version of Glue to be used by this session. \n                                      Currently, the only valid options are 2.0 and 3.0. \n                                      Default: 2.0.\n----\n\n## Selecting Job Types\n\n----\n    %streaming          String        Sets the session type to Glue Streaming.\n    %etl                String        Sets the session type to Glue ETL.\n    %glue_ray           String        Sets the session type to Glue Ray.\n----\n\n## Glue Config Magic \n*(common across all job types)*\n\n----\n\n    %%configure         Dictionary    A json-formatted dictionary consisting of all configuration parameters for \n                                      a session. Each parameter can be specified here or through individual magics.\n    %iam_role           String        Specify an IAM role ARN to execute your session with.\n                                      Default from ~/.aws/config on Linux or macOS, \n                                      or C:\\Users\\%USERNAME%\\.aws\\config` on Windows.\n    %number_of_workers  int           The number of workers of a defined worker_type that are allocated \n                                      when a session runs.\n                                      Default: 5.\n    %additional_python_modules  List  Comma separated list of additional Python modules to include in your cluster \n                                      (can be from Pypi or S3).\n----\n\n                                      \n## Magic for Spark Jobs (ETL & Streaming)\n\n----\n    %worker_type        String        Set the type of instances the session will use as workers. \n                                      ETL and Streaming support G.1X and G.2X. \n                                      Default: G.1X.\n    %connections        List          Specify a comma separated list of connections to use in the session.\n    %extra_py_files     List          Comma separated list of additional Python files From S3.\n    %extra_jars         List          Comma separated list of additional Jars to include in the cluster.\n    %spark_conf         String        Specify custom spark configurations for your session. \n                                      E.g. %spark_conf spark.serializer=org.apache.spark.serializer.KryoSerializer\n----\n                                      \n## Magic for Ray Job\n\n----\n    %min_workers        Int           The minimum number of workers that are allocated to a Ray job. \n                                      Default: 1.\n    %object_memory_head Int           The percentage of free memory on the instance head node after a warm start. \n                                      Minimum: 0. Maximum: 100.\n    %object_memory_worker Int         The percentage of free memory on the instance worker nodes after a warm start. \n                                      Minimum: 0. Maximum: 100.\n----\n\n## Action Magic\n\n----\n\n    %%sql               String        Run SQL code. All lines after the initial %%sql magic will be passed\n                                      as part of the SQL code.  \n----\n\n"
					},
					"metadata": {}
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "####  Run this cell to set up and start your interactive session.\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%idle_timeout 2880\n%glue_version 3.0\n%worker_type G.1X\n%number_of_workers 5\n\nimport sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\n\nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)",
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"execution_count": 1,
			"outputs": [
				{
					"name": "stdout",
					"text": "Current idle_timeout is 2880 minutes.\nidle_timeout has been set to 2880 minutes.\nSetting Glue version to: 3.0\nPrevious worker type: G.1X\nSetting new worker type to: G.1X\nPrevious number of workers: 5\nSetting new number of workers to: 5\nAuthenticating with environment variables and user-defined glue_role_arn: arn:aws:iam::883375387566:role/glue-full-access\nTrying to create a Glue session for the kernel.\nWorker Type: G.1X\nNumber of Workers: 5\nSession ID: 144285e4-a0c6-40c7-ad12-cd7df56562e3\nJob Type: glueetl\nApplying the following default arguments:\n--glue_kernel_version 0.37.0\n--enable-glue-datacatalog true\nWaiting for session 144285e4-a0c6-40c7-ad12-cd7df56562e3 to get into ready status...\nSession 144285e4-a0c6-40c7-ad12-cd7df56562e3 has been created.\n\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "#### Example: Create a DynamicFrame from a table in the AWS Glue Data Catalog and display its schema\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "#dyf = glueContext.create_dynamic_frame.from_catalog(database='database_name', table_name='table_name')\n#dyf.printSchema()\n\nimport pyspark\n  \n# TODO Pass job parameters externally\n#args={\"s3_bucket\": \"sorel-20m\", \"s3_key\": \"09-DEC-2020/binaries/0000029bfead495a003e43a7ab8406c6209ffb7d5e59dd212607aa358bfd66ea\"}\n#args={\"s3_bucket\": \"sorel-20m\", \"s3_key\": \"09-DEC-2020/binaries\"}\nargs={\"s3_bucket\": \"sorel-20m-demo\", \"s3_key\": \"tmp/binaries\"}\n\n'''\n2020-12-01 20:39:23     179128 0000029bfead495a003e43a7ab8406c6209ffb7d5e59dd212607aa358bfd66ea\n2020-12-01 20:39:23       1786 000003b99c3d4b9860ad0b0ca43450603e5322f2cca3c9b3d543a2d6440305a0\n2020-12-01 20:39:23    2687186 00000533148c26bcc09ab44b1acafe32dde93773d4a7e3dbd06c8232db5e437f\n2020-12-01 20:39:23     154064 000005920ff4eb85cfc74fd51ef1d5d7518dc16f6cb5c53f94f619473321d594\n2020-12-01 20:39:23     170646 000008cf1b5ecbed74f31b45e96e0fb6566b6af75a5cd87335aaa91c20a9b822\n2020-12-01 20:39:23     105479 000008e2ff1b8d64e3f81cbc456d4d51b6e967af0267d5486d4a562df291d0a6\n2020-12-01 20:39:23      44960 00000b37a3d68384e9ce2c8f969ba3d839514ec6d3b234ed2285dff2aee644bd\n2020-12-01 20:39:23     553005 00000cae80bac4c4591dd2f4451d0d1543ecd8d62eb8bcdc22a6bd45ba738d7d\n2020-12-01 20:39:23      70200 0000119640135ca4b5ee0d21459a1f841b9c030a88513581a272fc4740d78f48\n2020-12-01 20:39:29     489842 0000130e0c5d788a51b1c7e519b0883f0d34485076f9ceb11c1cda4929dffb31\n'''\n\nbucket = args['s3_bucket']\nkey = args['s3_key']\n\n#spark = pyspark.sql.SparkSession(sc)\n\nbinary_rdd = sc.binaryFiles(\"s3://{}/{}\".format(bucket, key))\n\n# do something with the binary_rdd\n",
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"execution_count": 8,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df = binary_rdd.filter(lambda key:key == 's3://sorel-20m-demo/tmp/binaries/0000029bfead495a003e43a7ab8406c6209ffb7d5e59dd212607aa358bfd66ea').toDF()\ndf.show()",
			"metadata": {
				"trusted": true
			},
			"execution_count": 9,
			"outputs": [
				{
					"name": "stdout",
					"text": "ValueError: RDD is empty\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "",
			"metadata": {
				"trusted": true
			},
			"execution_count": 12,
			"outputs": [
				{
					"name": "stderr",
					"text": "Illegal Session Status\n",
					"output_type": "stream"
				},
				{
					"name": "stdout",
					"text": "Statement 16 has been cancelled\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "#### Example: Convert the DynamicFrame to a Spark DataFrame and display a sample of the data\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "df = dyf.toDF()\ndf.show()",
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "markdown",
			"source": "#### Example: Write the data in the DynamicFrame to a location in Amazon S3 and a table for it in the AWS Glue Data Catalog\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "s3output = glueContext.getSink(\n  path=\"s3://bucket_name/folder_name\",\n  connection_type=\"s3\",\n  updateBehavior=\"UPDATE_IN_DATABASE\",\n  partitionKeys=[],\n  compression=\"snappy\",\n  enableUpdateCatalog=True,\n  transformation_ctx=\"s3output\",\n)\ns3output.setCatalogInfo(\n  catalogDatabase=\"demo\", catalogTableName=\"populations\"\n)\ns3output.setFormat(\"glueparquet\")\ns3output.writeFrame(DyF)",
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "%status\n%list_sessions",
			"metadata": {
				"trusted": true
			},
			"execution_count": 30,
			"outputs": [
				{
					"name": "stdout",
					"text": "Session ID: 3a26e41a-f615-4e0b-af93-751f9f952e7b\nStatus: READY\nRole: arn:aws:iam::883375387566:role/glue-full-access\nCreatedOn: 2023-03-16 01:27:17.085000+00:00\nGlueVersion: 3.0\nWorker Type: G.1X\nNumber of Workers: 5\nRegion: us-east-1\nApplying the following default arguments:\n--glue_kernel_version 0.37.0\n--enable-glue-datacatalog true\nArguments Passed: ['--glue_kernel_version: 0.37.0', '--enable-glue-datacatalog: true']\nThe first 23 sessions are:\n0aa03fd3-ab6f-4d85-b882-0be986a1fd22\n1816a59b-d194-41f3-9d12-02bf90a098c5\n1e367fb8-bf26-461f-b4b9-93a68db402b6\n260bffd6-27e8-4487-8fe9-e547b1f79a2d\n2fcace20-cec9-432d-9a60-6f67f5ff168b\n3a26e41a-f615-4e0b-af93-751f9f952e7b\n416957e6-debf-426a-bd40-eda3df323fad\n5618b7b1-d706-4b71-9aad-85dc985bd5fa\n5f3b1b5d-59eb-4114-9503-9b68058b4841\n62c54cec-660e-480b-b9cf-de0bc24f00dd\n6766e8da-9786-41fe-89a9-978c7d71a053\n697427db-8828-4441-82e9-e0cdf670eca0\n716a100f-e125-4d4b-b69a-d18724c86304\n82ae531d-206e-4d03-873e-f9733ec0cc71\n8692fbe3-e31c-43db-b4bd-7788c69fdf65\n8fd1ccd1-e001-463d-b26c-2c94b4d670d8\n94be9d3a-1aad-47df-8566-c4a786313278\naa598c53-03c6-4dc6-94be-5733e8cdd801\nbfe58f27-8c26-4e54-ac5c-7c5a81561e68\ncf345940-2c40-453e-9c3c-656dbd454444\nd832a791-052b-4491-bf7b-a4e4957a0c0e\nda84b4df-2bab-419b-904b-932edc29b267\ndf629284-b003-4637-822f-4e4d64339007\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "%stop_session",
			"metadata": {
				"trusted": true
			},
			"execution_count": 34,
			"outputs": [
				{
					"name": "stdout",
					"text": "There is no current session.\n",
					"output_type": "stream"
				}
			]
		}
	]
}