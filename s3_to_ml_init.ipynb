{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40d33410-af8a-44d0-a481-87133cad26f8",
   "metadata": {},
   "source": [
    "# Accessing many files in S3 via PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a17bb5-2da7-4244-a3ba-aef0546c2b04",
   "metadata": {},
   "source": [
    "Assume that we are using the PySpark kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a22f229-e8f7-40a8-a392-9c3cf6b82b52",
   "metadata": {},
   "source": [
    "## Read files recursively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed1c0d1d-debc-47c5-bc87-2f457a7fca36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T22:16:59.497097Z",
     "iopub.status.busy": "2022-04-18T22:16:59.496859Z",
     "iopub.status.idle": "2022-04-18T22:17:36.697967Z",
     "shell.execute_reply": "2022-04-18T22:17:36.697396Z",
     "shell.execute_reply.started": "2022-04-18T22:16:59.497072Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "660f2f50b1f648e580ddc98d910ef2bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>0</td><td>application_1650320080052_0002</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-25-143.us-east-2.compute.internal:20888/proxy/application_1650320080052_0002/\" class=\"emr-proxy-link\" emr-resource=\"j-25EIARB9Z1F3A\n",
       "\" application-id=\"application_1650320080052_0002\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-16-151.us-east-2.compute.internal:8042/node/containerlogs/container_1650320080052_0002_01_000001/livy\" >Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e93621ae-b94b-4f88-8e13-eb6016488463",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T22:17:36.699081Z",
     "iopub.status.busy": "2022-04-18T22:17:36.698902Z",
     "iopub.status.idle": "2022-04-18T22:18:42.366290Z",
     "shell.execute_reply": "2022-04-18T22:18:42.365573Z",
     "shell.execute_reply.started": "2022-04-18T22:17:36.699058Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6236cf33c5e0437a9211a7efb6a78ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://sparkbyexamples.com/spark/spark-read-binary-file-into-dataframe/\n",
    "#df = spark.read.format(\"image\").load(\"s3://multimedia-commons/data/images/000/\")\n",
    "df = spark.read.format(\"image\").option(\"recursiveFileLookup\", True).load(\"s3://multimedia-commons/data/images/00*\")\n",
    "#df = spark.read.format(\"image\").option(\"recursiveFileLookup\", True).load(\"s3://multimedia-commons/data/images/{00*,01*}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "facaf944-c50a-471c-9b63-a88fa60801d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T22:18:42.367906Z",
     "iopub.status.busy": "2022-04-18T22:18:42.367674Z",
     "iopub.status.idle": "2022-04-18T22:18:46.332054Z",
     "shell.execute_reply": "2022-04-18T22:18:46.331415Z",
     "shell.execute_reply.started": "2022-04-18T22:18:42.367873Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20e1d491f869495e8b1ae9b2f84fac46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1501"
     ]
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03649357-370c-4670-a379-ca57d4892022",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T22:18:46.333313Z",
     "iopub.status.busy": "2022-04-18T22:18:46.333139Z",
     "iopub.status.idle": "2022-04-18T22:18:46.400795Z",
     "shell.execute_reply": "2022-04-18T22:18:46.400169Z",
     "shell.execute_reply.started": "2022-04-18T22:18:46.333292Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bc6553f72b14b09910ac3c581909e45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@title Helper functions for loading image (hidden)\n",
    "\n",
    "original_image_cache = {}\n",
    "\n",
    "def preprocess_image(image):\n",
    "  image = np.array(image)\n",
    "  # reshape into shape [batch_size, height, width, num_channels]\n",
    "  img_reshaped = tf.reshape(image, [1, image.shape[0], image.shape[1], image.shape[2]])\n",
    "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "  image = tf.image.convert_image_dtype(img_reshaped, tf.float32)\n",
    "  return image\n",
    "\n",
    "def load_image_from_url(img_url):\n",
    "  \"\"\"Returns an image with shape [1, height, width, num_channels].\"\"\"\n",
    "  user_agent = {'User-agent': 'Colab Sample (https://tensorflow.org)'}\n",
    "  response = requests.get(img_url, headers=user_agent)\n",
    "  image = Image.open(BytesIO(response.content))\n",
    "  image = preprocess_image(image)\n",
    "  return image\n",
    "\n",
    "def load_image(image_url, image_size=256, dynamic_size=False, max_dynamic_size=512):\n",
    "  \"\"\"Loads and preprocesses images.\"\"\"\n",
    "  # Cache image file locally.\n",
    "  if image_url in original_image_cache:\n",
    "    img = original_image_cache[image_url]\n",
    "  elif image_url.startswith('https://'):\n",
    "    img = load_image_from_url(image_url)\n",
    "  else:\n",
    "    fd = tf.io.gfile.GFile(image_url, 'rb')\n",
    "    img = preprocess_image(Image.open(fd))\n",
    "  original_image_cache[image_url] = img\n",
    "  # Load and convert to float32 numpy array, add batch dimension, and normalize to range [0, 1].\n",
    "  img_raw = img\n",
    "  if tf.reduce_max(img) > 1.0:\n",
    "    img = img / 255.\n",
    "  if len(img.shape) == 3:\n",
    "    img = tf.stack([img, img, img], axis=-1)\n",
    "  if not dynamic_size:\n",
    "    img = tf.image.resize_with_pad(img, image_size, image_size)\n",
    "  elif img.shape[1] > max_dynamic_size or img.shape[2] > max_dynamic_size:\n",
    "    img = tf.image.resize_with_pad(img, max_dynamic_size, max_dynamic_size)\n",
    "  return img, img_raw\n",
    "\n",
    "def show_image(image, title=''):\n",
    "  image_size = image.shape[1]\n",
    "  w = (image_size * 6) // 320\n",
    "  plt.figure(figsize=(w, w))\n",
    "  plt.imshow(image[0], aspect='equal')\n",
    "  plt.axis('off')\n",
    "  plt.title(title)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a511f34-95cd-41ff-8f6e-c2606cf26347",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T22:18:46.403433Z",
     "iopub.status.busy": "2022-04-18T22:18:46.403257Z",
     "iopub.status.idle": "2022-04-18T22:18:46.680608Z",
     "shell.execute_reply": "2022-04-18T22:18:46.679843Z",
     "shell.execute_reply.started": "2022-04-18T22:18:46.403411Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa8a663ead9643208ffed53474f40dc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected model: efficientnetv2-s : https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_s/classification/2\n",
      "Images will be converted to 384x384\n",
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt\n",
      "16384/10484 [==============================================] - 0s 0us/step"
     ]
    }
   ],
   "source": [
    "#@title Select an Image Classification model\n",
    "\n",
    "image_size = 224\n",
    "dynamic_size = False\n",
    "\n",
    "model_name = \"efficientnetv2-s\" # @param ['efficientnetv2-s', 'efficientnetv2-m', 'efficientnetv2-l', 'efficientnetv2-s-21k', 'efficientnetv2-m-21k', 'efficientnetv2-l-21k', 'efficientnetv2-xl-21k', 'efficientnetv2-b0-21k', 'efficientnetv2-b1-21k', 'efficientnetv2-b2-21k', 'efficientnetv2-b3-21k', 'efficientnetv2-s-21k-ft1k', 'efficientnetv2-m-21k-ft1k', 'efficientnetv2-l-21k-ft1k', 'efficientnetv2-xl-21k-ft1k', 'efficientnetv2-b0-21k-ft1k', 'efficientnetv2-b1-21k-ft1k', 'efficientnetv2-b2-21k-ft1k', 'efficientnetv2-b3-21k-ft1k', 'efficientnetv2-b0', 'efficientnetv2-b1', 'efficientnetv2-b2', 'efficientnetv2-b3', 'efficientnet_b0', 'efficientnet_b1', 'efficientnet_b2', 'efficientnet_b3', 'efficientnet_b4', 'efficientnet_b5', 'efficientnet_b6', 'efficientnet_b7', 'bit_s-r50x1', 'inception_v3', 'inception_resnet_v2', 'resnet_v1_50', 'resnet_v1_101', 'resnet_v1_152', 'resnet_v2_50', 'resnet_v2_101', 'resnet_v2_152', 'nasnet_large', 'nasnet_mobile', 'pnasnet_large', 'mobilenet_v2_100_224', 'mobilenet_v2_130_224', 'mobilenet_v2_140_224', 'mobilenet_v3_small_100_224', 'mobilenet_v3_small_075_224', 'mobilenet_v3_large_100_224', 'mobilenet_v3_large_075_224']\n",
    "\n",
    "model_handle_map = {\n",
    "  \"efficientnetv2-s\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_s/classification/2\",\n",
    "  \"efficientnetv2-m\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_m/classification/2\",\n",
    "  \"efficientnetv2-l\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_l/classification/2\",\n",
    "  \"efficientnetv2-s-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_s/classification/2\",\n",
    "  \"efficientnetv2-m-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_m/classification/2\",\n",
    "  \"efficientnetv2-l-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_l/classification/2\",\n",
    "  \"efficientnetv2-xl-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_xl/classification/2\",\n",
    "  \"efficientnetv2-b0-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_b0/classification/2\",\n",
    "  \"efficientnetv2-b1-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_b1/classification/2\",\n",
    "  \"efficientnetv2-b2-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_b2/classification/2\",\n",
    "  \"efficientnetv2-b3-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_b3/classification/2\",\n",
    "  \"efficientnetv2-s-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_s/classification/2\",\n",
    "  \"efficientnetv2-m-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_m/classification/2\",\n",
    "  \"efficientnetv2-l-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_l/classification/2\",\n",
    "  \"efficientnetv2-xl-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_xl/classification/2\",\n",
    "  \"efficientnetv2-b0-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_b0/classification/2\",\n",
    "  \"efficientnetv2-b1-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_b1/classification/2\",\n",
    "  \"efficientnetv2-b2-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_b2/classification/2\",\n",
    "  \"efficientnetv2-b3-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_b3/classification/2\",\n",
    "  \"efficientnetv2-b0\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b0/classification/2\",\n",
    "  \"efficientnetv2-b1\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b1/classification/2\",\n",
    "  \"efficientnetv2-b2\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b2/classification/2\",\n",
    "  \"efficientnetv2-b3\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b3/classification/2\",\n",
    "  \"efficientnet_b0\": \"https://tfhub.dev/tensorflow/efficientnet/b0/classification/1\",\n",
    "  \"efficientnet_b1\": \"https://tfhub.dev/tensorflow/efficientnet/b1/classification/1\",\n",
    "  \"efficientnet_b2\": \"https://tfhub.dev/tensorflow/efficientnet/b2/classification/1\",\n",
    "  \"efficientnet_b3\": \"https://tfhub.dev/tensorflow/efficientnet/b3/classification/1\",\n",
    "  \"efficientnet_b4\": \"https://tfhub.dev/tensorflow/efficientnet/b4/classification/1\",\n",
    "  \"efficientnet_b5\": \"https://tfhub.dev/tensorflow/efficientnet/b5/classification/1\",\n",
    "  \"efficientnet_b6\": \"https://tfhub.dev/tensorflow/efficientnet/b6/classification/1\",\n",
    "  \"efficientnet_b7\": \"https://tfhub.dev/tensorflow/efficientnet/b7/classification/1\",\n",
    "  \"bit_s-r50x1\": \"https://tfhub.dev/google/bit/s-r50x1/ilsvrc2012_classification/1\",\n",
    "  \"inception_v3\": \"https://tfhub.dev/google/imagenet/inception_v3/classification/4\",\n",
    "  \"inception_resnet_v2\": \"https://tfhub.dev/google/imagenet/inception_resnet_v2/classification/4\",\n",
    "  \"resnet_v1_50\": \"https://tfhub.dev/google/imagenet/resnet_v1_50/classification/4\",\n",
    "  \"resnet_v1_101\": \"https://tfhub.dev/google/imagenet/resnet_v1_101/classification/4\",\n",
    "  \"resnet_v1_152\": \"https://tfhub.dev/google/imagenet/resnet_v1_152/classification/4\",\n",
    "  \"resnet_v2_50\": \"https://tfhub.dev/google/imagenet/resnet_v2_50/classification/4\",\n",
    "  \"resnet_v2_101\": \"https://tfhub.dev/google/imagenet/resnet_v2_101/classification/4\",\n",
    "  \"resnet_v2_152\": \"https://tfhub.dev/google/imagenet/resnet_v2_152/classification/4\",\n",
    "  \"nasnet_large\": \"https://tfhub.dev/google/imagenet/nasnet_large/classification/4\",\n",
    "  \"nasnet_mobile\": \"https://tfhub.dev/google/imagenet/nasnet_mobile/classification/4\",\n",
    "  \"pnasnet_large\": \"https://tfhub.dev/google/imagenet/pnasnet_large/classification/4\",\n",
    "  \"mobilenet_v2_100_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4\",\n",
    "  \"mobilenet_v2_130_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4\",\n",
    "  \"mobilenet_v2_140_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/classification/4\",\n",
    "  \"mobilenet_v3_small_100_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v3_small_100_224/classification/5\",\n",
    "  \"mobilenet_v3_small_075_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v3_small_075_224/classification/5\",\n",
    "  \"mobilenet_v3_large_100_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/classification/5\",\n",
    "  \"mobilenet_v3_large_075_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v3_large_075_224/classification/5\",\n",
    "}\n",
    "\n",
    "model_image_size_map = {\n",
    "  \"efficientnetv2-s\": 384,\n",
    "  \"efficientnetv2-m\": 480,\n",
    "  \"efficientnetv2-l\": 480,\n",
    "  \"efficientnetv2-b0\": 224,\n",
    "  \"efficientnetv2-b1\": 240,\n",
    "  \"efficientnetv2-b2\": 260,\n",
    "  \"efficientnetv2-b3\": 300,\n",
    "  \"efficientnetv2-s-21k\": 384,\n",
    "  \"efficientnetv2-m-21k\": 480,\n",
    "  \"efficientnetv2-l-21k\": 480,\n",
    "  \"efficientnetv2-xl-21k\": 512,\n",
    "  \"efficientnetv2-b0-21k\": 224,\n",
    "  \"efficientnetv2-b1-21k\": 240,\n",
    "  \"efficientnetv2-b2-21k\": 260,\n",
    "  \"efficientnetv2-b3-21k\": 300,\n",
    "  \"efficientnetv2-s-21k-ft1k\": 384,\n",
    "  \"efficientnetv2-m-21k-ft1k\": 480,\n",
    "  \"efficientnetv2-l-21k-ft1k\": 480,\n",
    "  \"efficientnetv2-xl-21k-ft1k\": 512,\n",
    "  \"efficientnetv2-b0-21k-ft1k\": 224,\n",
    "  \"efficientnetv2-b1-21k-ft1k\": 240,\n",
    "  \"efficientnetv2-b2-21k-ft1k\": 260,\n",
    "  \"efficientnetv2-b3-21k-ft1k\": 300, \n",
    "  \"efficientnet_b0\": 224,\n",
    "  \"efficientnet_b1\": 240,\n",
    "  \"efficientnet_b2\": 260,\n",
    "  \"efficientnet_b3\": 300,\n",
    "  \"efficientnet_b4\": 380,\n",
    "  \"efficientnet_b5\": 456,\n",
    "  \"efficientnet_b6\": 528,\n",
    "  \"efficientnet_b7\": 600,\n",
    "  \"inception_v3\": 299,\n",
    "  \"inception_resnet_v2\": 299,\n",
    "  \"mobilenet_v2_100_224\": 224,\n",
    "  \"mobilenet_v2_130_224\": 224,\n",
    "  \"mobilenet_v2_140_224\": 224,\n",
    "  \"nasnet_large\": 331,\n",
    "  \"nasnet_mobile\": 224,\n",
    "  \"pnasnet_large\": 331,\n",
    "  \"resnet_v1_50\": 224,\n",
    "  \"resnet_v1_101\": 224,\n",
    "  \"resnet_v1_152\": 224,\n",
    "  \"resnet_v2_50\": 224,\n",
    "  \"resnet_v2_101\": 224,\n",
    "  \"resnet_v2_152\": 224,\n",
    "  \"mobilenet_v3_small_100_224\": 224,\n",
    "  \"mobilenet_v3_small_075_224\": 224,\n",
    "  \"mobilenet_v3_large_100_224\": 224,\n",
    "  \"mobilenet_v3_large_075_224\": 224,\n",
    "}\n",
    "\n",
    "model_handle = model_handle_map[model_name]\n",
    "\n",
    "print(f\"Selected model: {model_name} : {model_handle}\")\n",
    "\n",
    "\n",
    "max_dynamic_size = 512\n",
    "if model_name in model_image_size_map:\n",
    "  image_size = model_image_size_map[model_name]\n",
    "  dynamic_size = False\n",
    "  print(f\"Images will be converted to {image_size}x{image_size}\")\n",
    "else:\n",
    "  dynamic_size = True\n",
    "  print(f\"Images will be capped to a max size of {max_dynamic_size}x{max_dynamic_size}\")\n",
    "\n",
    "labels_file = \"https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt\"\n",
    "\n",
    "#download labels and creates a maps\n",
    "downloaded_file = tf.keras.utils.get_file(\"labels.txt\", origin=labels_file)\n",
    "\n",
    "classes = []\n",
    "\n",
    "with open(downloaded_file) as f:\n",
    "  labels = f.readlines()\n",
    "  classes = [l.strip() for l in labels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dcb80e1-6449-431c-babf-e3cd977bb85e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T22:18:46.682158Z",
     "iopub.status.busy": "2022-04-18T22:18:46.681751Z",
     "iopub.status.idle": "2022-04-18T22:18:49.997488Z",
     "shell.execute_reply": "2022-04-18T22:18:49.996884Z",
     "shell.execute_reply.started": "2022-04-18T22:18:46.682121Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92e0e4bb952e4a758ba097cd000363b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- image: struct (nullable = true)\n",
      " |    |-- origin: string (nullable = true)\n",
      " |    |-- height: integer (nullable = true)\n",
      " |    |-- width: integer (nullable = true)\n",
      " |    |-- nChannels: integer (nullable = true)\n",
      " |    |-- mode: integer (nullable = true)\n",
      " |    |-- data: binary (nullable = true)"
     ]
    }
   ],
   "source": [
    "first_row = df.first()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eca89597-d001-4866-a291-995886fc4dd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T22:28:57.145998Z",
     "iopub.status.busy": "2022-04-18T22:28:57.145771Z",
     "iopub.status.idle": "2022-04-18T22:28:57.208477Z",
     "shell.execute_reply": "2022-04-18T22:28:57.207903Z",
     "shell.execute_reply.started": "2022-04-18T22:28:57.145972Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "429a1be0b6d2409aac1e3c020cdc6488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO Make into a PySpark function\n",
    "def to_img(row):\n",
    "    row_dict = row.asDict()  \n",
    "    image_dict = row_dict['image'].asDict()\n",
    "    image_data = image_dict['data']\n",
    "    h = image_dict['height']\n",
    "    w = image_dict['width']\n",
    "    c = image_dict['nChannels']\n",
    "    img_b = bytes(image_data)\n",
    "    # https://stackoverflow.com/a/50026948/11262633\n",
    "    img_pil = Image.frombytes('RGB', (h,w), img_b, 'raw')\n",
    "    return img_pil, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5447af4d-f905-42b9-b954-9b549af4d6c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T22:28:58.395179Z",
     "iopub.status.busy": "2022-04-18T22:28:58.394948Z",
     "iopub.status.idle": "2022-04-18T22:28:58.463051Z",
     "shell.execute_reply": "2022-04-18T22:28:58.462495Z",
     "shell.execute_reply.started": "2022-04-18T22:28:58.395154Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "940e81cf4ffc471c9e8f7bf760ccee0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, c = to_img(first_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a797c65-473a-4cfe-9f33-a3b711448c88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T22:29:29.552109Z",
     "iopub.status.busy": "2022-04-18T22:29:29.551848Z",
     "iopub.status.idle": "2022-04-18T22:29:46.908709Z",
     "shell.execute_reply": "2022-04-18T22:29:46.907778Z",
     "shell.execute_reply.started": "2022-04-18T22:29:29.552084Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f68a9a4c84743c48d74f5a9f6b60ed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = hub.load(model_handle)\n",
    "\n",
    "input_shape = (1, image.size[0], image.size[1], c) #image.shape\n",
    "warmup_input = tf.random.uniform(input_shape, 0, 1.0)\n",
    "warmup_logits = classifier(warmup_input).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4557f1c-9e80-4a48-b7a4-e62ce7f73b8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T22:29:50.459383Z",
     "iopub.status.busy": "2022-04-18T22:29:50.459155Z",
     "iopub.status.idle": "2022-04-18T22:30:07.812595Z",
     "shell.execute_reply": "2022-04-18T22:30:07.812006Z",
     "shell.execute_reply.started": "2022-04-18T22:29:50.459358Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61731ba81b2c41c0aa0097f67e78344d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rows = df.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "469828c7-2195-4015-b940-569f351876a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T22:31:58.554953Z",
     "iopub.status.busy": "2022-04-18T22:31:58.554722Z",
     "iopub.status.idle": "2022-04-18T22:31:58.614027Z",
     "shell.execute_reply": "2022-04-18T22:31:58.613385Z",
     "shell.execute_reply.started": "2022-04-18T22:31:58.554928Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f2b2097fdf48ddba337bd72f72449f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (480, 640) 3\n",
      "1 (344, 500) 3\n",
      "2 (500, 375) 3\n",
      "3 (500, 500) 3\n",
      "4 (400, 500) 3\n",
      "5 (500, 375) 3\n",
      "6 (375, 500) 3\n",
      "7 (375, 500) 3\n",
      "8 (500, 500) 3\n",
      "9 (375, 500) 3"
     ]
    }
   ],
   "source": [
    "for idx, row in enumerate(rows):\n",
    "    image, c = to_img(row)\n",
    "    print(idx, image.size, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1b060f5d-69d8-48b1-9090-c6ff17d74901",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T22:43:22.603477Z",
     "iopub.status.busy": "2022-04-18T22:43:22.603248Z",
     "iopub.status.idle": "2022-04-18T22:43:22.658568Z",
     "shell.execute_reply": "2022-04-18T22:43:22.658034Z",
     "shell.execute_reply.started": "2022-04-18T22:43:22.603452Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d809ed5ce64d22a0567a1e33906452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def img_to_t(image):\n",
    "    return preprocess_image(image)\n",
    "\n",
    "def to_img_t(row):\n",
    "    image, c = to_img(row)\n",
    "    return img_to_t(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4fc3f33f-5070-48b8-ad9b-bfed3b7a335a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T22:46:18.665714Z",
     "iopub.status.busy": "2022-04-18T22:46:18.665480Z",
     "iopub.status.idle": "2022-04-18T22:46:40.045236Z",
     "shell.execute_reply": "2022-04-18T22:46:40.044631Z",
     "shell.execute_reply.started": "2022-04-18T22:46:18.665689Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39bc5f4ae7cc4679bb68dfc745831f56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1)  905 - window screen: 0.6953913569450378\n",
      "(2)  886 - velvet: 0.052281565964221954\n",
      "(3)  754 - radiator: 0.01766561158001423\n",
      "(4)  906 - window shade: 0.01263257022947073\n",
      "(5)  557 - fire screen: 0.00539223849773407\n",
      "(1)  886 - velvet: 0.3687962591648102\n",
      "(2)  912 - wool: 0.33010637760162354\n",
      "(3)  742 - prayer rug: 0.09726077318191528\n",
      "(4)  540 - doormat: 0.02379644103348255\n",
      "(5)  550 - envelope: 0.005731997545808554\n",
      "(1)  905 - window screen: 0.35413026809692383\n",
      "(2)  886 - velvet: 0.33055585622787476\n",
      "(3)  557 - fire screen: 0.02747790887951851\n",
      "(4)  742 - prayer rug: 0.018723148852586746\n",
      "(5)  592 - handkerchief: 0.015232972800731659\n",
      "(1)  749 - purse: 0.3934866189956665\n",
      "(2)  680 - necklace: 0.30827441811561584\n",
      "(3)  773 - safety pin: 0.03285354748368263\n",
      "(4)  768 - rubber eraser: 0.030108686536550522\n",
      "(5)  601 - hook: 0.01759233884513378"
     ]
    }
   ],
   "source": [
    "# TODO Use a custom function, not a loop\n",
    "for idx, row in enumerate(rows):\n",
    "    \n",
    "    image = to_img_t(row)\n",
    "    \n",
    "    # Run model on image\n",
    "    probabilities = tf.nn.softmax(classifier(image)).numpy()\n",
    "\n",
    "    top_5 = tf.argsort(probabilities, axis=-1, direction=\"DESCENDING\")[0][:5].numpy()\n",
    "    np_classes = np.array(classes)\n",
    "\n",
    "    # Some models include an additional 'background' class in the predictions, so\n",
    "    # we must account for this when reading the class labels.\n",
    "    includes_background_class = probabilities.shape[1] == 1001\n",
    "\n",
    "    for i, item in enumerate(top_5):\n",
    "      class_index = item if includes_background_class else item + 1\n",
    "      line = f'({i+1}) {class_index:4} - {classes[class_index]}: {probabilities[0][top_5][i]}'\n",
    "      print(line)\n",
    "\n",
    "    #show_image(image, '')\n",
    "    \n",
    "    if idx > 2:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
