{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d21936fd-b125-4c5f-8aa9-45469c260062",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T02:52:47.185698Z",
     "iopub.status.busy": "2022-04-20T02:52:47.185473Z",
     "iopub.status.idle": "2022-04-20T02:52:47.245399Z",
     "shell.execute_reply": "2022-04-20T02:52:47.244714Z",
     "shell.execute_reply.started": "2022-04-20T02:52:47.185674Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43f41933a7b04b2a88edeb4e00885a7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17aa5a4c-c74f-489a-aa2f-749237f1bf56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T02:27:43.496751Z",
     "iopub.status.busy": "2022-04-20T02:27:43.496527Z",
     "iopub.status.idle": "2022-04-20T02:35:30.295582Z",
     "shell.execute_reply": "2022-04-20T02:35:30.294956Z",
     "shell.execute_reply.started": "2022-04-20T02:27:43.496728Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2daad24cbb134ebbbc0363e950840839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- image: struct (nullable = true)\n",
      " |    |-- origin: string (nullable = true)\n",
      " |    |-- height: integer (nullable = true)\n",
      " |    |-- width: integer (nullable = true)\n",
      " |    |-- nChannels: integer (nullable = true)\n",
      " |    |-- mode: integer (nullable = true)\n",
      " |    |-- data: binary (nullable = true)\n",
      "\n",
      "27288"
     ]
    }
   ],
   "source": [
    "# https://sparkbyexamples.com/spark/spark-read-binary-file-into-dataframe/\n",
    "df = spark.read.format(\"image\").option(\"recursiveFileLookup\", True).load(\"s3://multimedia-commons/data/images/{00*,01*}\")\n",
    "df.printSchema()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f6a929-6f27-4bae-b744-119f7c5bf8d6",
   "metadata": {},
   "source": [
    "## Use the built-in ```toNDArray``` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "51335725-4f51-4be9-a64d-cc507b79ef89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T02:55:40.663163Z",
     "iopub.status.busy": "2022-04-20T02:55:40.662941Z",
     "iopub.status.idle": "2022-04-20T02:57:06.131722Z",
     "shell.execute_reply": "2022-04-20T02:57:06.130889Z",
     "shell.execute_reply.started": "2022-04-20T02:55:40.663139Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baf416d17a494c11bacedc8a1823ddd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "\n",
      "  An exception was thrown from the Python worker. Please see the stack trace below.\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/yarn/usercache/livy/appcache/application_1650412208045_0005/container_1650412208045_0005_01_000016/pyspark.zip/pyspark/worker.py\", line 604, in main\n",
      "    process()\n",
      "  File \"/mnt/yarn/usercache/livy/appcache/application_1650412208045_0005/container_1650412208045_0005_01_000016/pyspark.zip/pyspark/worker.py\", line 596, in process\n",
      "    serializer.dump_stream(out_iter, outfile)\n",
      "  File \"/mnt/yarn/usercache/livy/appcache/application_1650412208045_0005/container_1650412208045_0005_01_000016/pyspark.zip/pyspark/serializers.py\", line 211, in dump_stream\n",
      "    self.serializer.dump_stream(self._batched(iterator), stream)\n",
      "  File \"/mnt/yarn/usercache/livy/appcache/application_1650412208045_0005/container_1650412208045_0005_01_000016/pyspark.zip/pyspark/serializers.py\", line 132, in dump_stream\n",
      "    for obj in iterator:\n",
      "  File \"/mnt/yarn/usercache/livy/appcache/application_1650412208045_0005/container_1650412208045_0005_01_000016/pyspark.zip/pyspark/serializers.py\", line 200, in _batched\n",
      "    for item in iterator:\n",
      "  File \"/mnt/yarn/usercache/livy/appcache/application_1650412208045_0005/container_1650412208045_0005_01_000016/pyspark.zip/pyspark/worker.py\", line 450, in mapper\n",
      "    result = tuple(f(*[a[o] for o in arg_offsets]) for (arg_offsets, f) in udfs)\n",
      "  File \"/mnt/yarn/usercache/livy/appcache/application_1650412208045_0005/container_1650412208045_0005_01_000016/pyspark.zip/pyspark/worker.py\", line 450, in <genexpr>\n",
      "    result = tuple(f(*[a[o] for o in arg_offsets]) for (arg_offsets, f) in udfs)\n",
      "  File \"/mnt/yarn/usercache/livy/appcache/application_1650412208045_0005/container_1650412208045_0005_01_000016/pyspark.zip/pyspark/worker.py\", line 83, in <lambda>\n",
      "    return lambda *a: toInternal(f(*a))\n",
      "  File \"/mnt/yarn/usercache/livy/appcache/application_1650412208045_0005/container_1650412208045_0005_01_000016/pyspark.zip/pyspark/util.py\", line 87, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"<stdin>\", line 6, in <lambda>\n",
      "  File \"/mnt/yarn/usercache/livy/appcache/application_1650412208045_0005/container_1650412208045_0005_01_000016/pyspark.zip/pyspark/ml/image.py\", line 178, in toNDArray\n",
      "    strides=(width * nChannels, nChannels, 1))\n",
      "ValueError: strides is incompatible with shape of requested array and size of buffer\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py\", line 485, in show\n",
      "    print(self._jdf.showString(n, 20, vertical))\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1305, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/utils.py\", line 117, in deco\n",
      "    raise converted from None\n",
      "pyspark.sql.utils.PythonException: \n",
      "  An exception was thrown from the Python worker. Please see the stack trace below.\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/yarn/usercache/livy/appcache/application_1650412208045_0005/container_1650412208045_0005_01_000016/pyspark.zip/pyspark/worker.py\", line 604, in main\n",
      "    process()\n",
      "  File \"/mnt/yarn/usercache/livy/appcache/application_1650412208045_0005/container_1650412208045_0005_01_000016/pyspark.zip/pyspark/worker.py\", line 596, in process\n",
      "    serializer.dump_stream(out_iter, outfile)\n",
      "  File \"/mnt/yarn/usercache/livy/appcache/application_1650412208045_0005/container_1650412208045_0005_01_000016/pyspark.zip/pyspark/serializers.py\", line 211, in dump_stream\n",
      "    self.serializer.dump_stream(self._batched(iterator), stream)\n",
      "  File \"/mnt/yarn/usercache/livy/appcache/application_1650412208045_0005/container_1650412208045_0005_01_000016/pyspark.zip/pyspark/serializers.py\", line 132, in dump_stream\n",
      "    for obj in iterator:\n",
      "  File \"/mnt/yarn/usercache/livy/appcache/application_1650412208045_0005/container_1650412208045_0005_01_000016/pyspark.zip/pyspark/serializers.py\", line 200, in _batched\n",
      "    for item in iterator:\n",
      "  File \"/mnt/yarn/usercache/livy/appcache/application_1650412208045_0005/container_1650412208045_0005_01_000016/pyspark.zip/pyspark/worker.py\", line 450, in mapper\n",
      "    result = tuple(f(*[a[o] for o in arg_offsets]) for (arg_offsets, f) in udfs)\n",
      "  File \"/mnt/yarn/usercache/livy/appcache/application_1650412208045_0005/container_1650412208045_0005_01_000016/pyspark.zip/pyspark/worker.py\", line 450, in <genexpr>\n",
      "    result = tuple(f(*[a[o] for o in arg_offsets]) for (arg_offsets, f) in udfs)\n",
      "  File \"/mnt/yarn/usercache/livy/appcache/application_1650412208045_0005/container_1650412208045_0005_01_000016/pyspark.zip/pyspark/worker.py\", line 83, in <lambda>\n",
      "    return lambda *a: toInternal(f(*a))\n",
      "  File \"/mnt/yarn/usercache/livy/appcache/application_1650412208045_0005/container_1650412208045_0005_01_000016/pyspark.zip/pyspark/util.py\", line 87, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"<stdin>\", line 6, in <lambda>\n",
      "  File \"/mnt/yarn/usercache/livy/appcache/application_1650412208045_0005/container_1650412208045_0005_01_000016/pyspark.zip/pyspark/ml/image.py\", line 178, in toNDArray\n",
      "    strides=(width * nChannels, nChannels, 1))\n",
      "ValueError: strides is incompatible with shape of requested array and size of buffer\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/a/69215982/11262633\n",
    "img2shape = F.udf(lambda x: DenseVector(ImageSchema.toNDArray(x).shape), VectorUDT())\n",
    "\n",
    "df_new = df.withColumn('shape',img2vec('image'))\n",
    "df_new.show()\n",
    "#df_new.select('vecs').first().asDict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9efc654e-33e7-494f-82a2-f37013877a2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T03:02:53.766218Z",
     "iopub.status.busy": "2022-04-20T03:02:53.765884Z",
     "iopub.status.idle": "2022-04-20T03:04:03.211899Z",
     "shell.execute_reply": "2022-04-20T03:04:03.211300Z",
     "shell.execute_reply.started": "2022-04-20T03:02:53.766178Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f80f4e021a864e268128e1a281693128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image fields = ['origin', 'height', 'width', 'nChannels', 'mode', 'data']\n",
      "+--------------------+--------------------+\n",
      "|               image|                vecs|\n",
      "+--------------------+--------------------+\n",
      "|{s3://multimedia-...|[197.0,198.0,198....|\n",
      "|{s3://multimedia-...|                null|\n",
      "|{s3://multimedia-...|[0.0,149.0,128.0,...|\n",
      "|{s3://multimedia-...|[40.0,52.0,153.0,...|\n",
      "|{s3://multimedia-...|[127.0,111.0,229....|\n",
      "|{s3://multimedia-...|[42.0,143.0,128.0...|\n",
      "|{s3://multimedia-...|[253.0,253.0,253....|\n",
      "|{s3://multimedia-...|[14.0,10.0,9.0,10...|\n",
      "|{s3://multimedia-...|[45.0,108.0,52.0,...|\n",
      "|{s3://multimedia-...|[104.0,53.0,33.0,...|\n",
      "|{s3://multimedia-...|[0.0,0.0,0.0,0.0,...|\n",
      "|{s3://multimedia-...|[209.0,197.0,101....|\n",
      "|{s3://multimedia-...|[118.0,100.0,71.0...|\n",
      "|{s3://multimedia-...|[244.0,248.0,253....|\n",
      "|{s3://multimedia-...|[238.0,250.0,254....|\n",
      "|{s3://multimedia-...|[131.0,220.0,217....|\n",
      "|{s3://multimedia-...|[219.0,194.0,174....|\n",
      "|{s3://multimedia-...|[1.0,1.0,1.0,0.0,...|\n",
      "|{s3://multimedia-...|[0.0,0.0,36.0,0.0...|\n",
      "|{s3://multimedia-...|[20.0,119.0,71.0,...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/a/69215982/11262633\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml.image import ImageSchema\n",
    "from pyspark.ml.linalg import DenseVector, VectorUDT\n",
    "\n",
    "@F.udf(returnType=VectorUDT())\n",
    "def img2vec(x):\n",
    "    try:\n",
    "        image_np = DenseVector(ImageSchema.toNDArray(x).flatten())\n",
    "    except:\n",
    "        image_np = None\n",
    "    return image_np\n",
    "\n",
    "print(f'Image fields = {ImageSchema.imageFields}')\n",
    "df_new = df.withColumn('vecs',img2vec('image'))\n",
    "df_new.show()\n",
    "#df_new.select('vecs').first().asDict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16ad643-9487-44df-a25b-d5343f3e665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a long time\n",
    "df_new.where(df_new.vecs.isNull()).select('image.origin').show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
